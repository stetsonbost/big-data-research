# Research Log

This is a log of my progress for my big data research with Professor Weiqing Gu at Harvey Mudd College during Summer 2017. The format of these log entries may change over time as I settle on a comforable style for them.

## Tuesday, May 16

For this research, it is essential that I (re)learn core concepts of big data. As such, I am spending the first part of the research studying these. 

Today I set up my account on the Pittsburgh Supercomputing Center (PSC) server for the [XSEDE big data workshop](https://www.psc.edu/136-users/training/2554-xsede-hpc-workshop-may-18-19-2017-big-data) that is taking place on Thursday and Friday. I also looked at the main slides they will be using on Thursday ([Intro to Big Data](https://www.psc.edu/images/xsedetraining/BigDataFebruary2017/Intro_To_Big_Data.pdf), [Hadoop](https://www.psc.edu/images/xsedetraining/BigDataFebruary2017/BigData_Hadoop_110116.pdf), and [Spark](https://www.psc.edu/images/xsedetraining/BigDataFebruary2017/BigData_Hadoop_110116.pdf)). While these gave me a good idea of what would be covered in the workshop, it's obvious that it will be a very hands-on workshop that will teach me how to use popular computational tools like Hadoop and Spark for big data analytics.

In addition to preparing for the workshop, I also started studying material from Andrew Ng's course [CS 229: Machine Learning](http://cs229.stanford.edu/materials.html), taught at Stanford. I am beginning with his [first set of notes](http://cs229.stanford.edu/notes/cs229-notes1.pdf). It starts with an introduction to supervised learning, followed by a large section on linear regression. One thing he does is introduce the least-squares cost function, although I think several other cost functions could also be effective for linear regression. Ng talks about the least means squares (LMS) (aka Widrow-Hoff) learning rule, which makes updates to the weights of feature based on the current weight, error term, and the learning rate. An algorithm that does this is *batch gradient descent*, which works best if there is only one global optimum and no local optima. Another algorithm, *stochastic (incremental) gradient descent*, makes more frequent updates to the weights and can get to an optimum faster than batch gradient descent, making it better for larger training sets. The next part is more about how to deal with matrices and vectors, including least squares with matrices. This leads up to the normal equation, which will be very important.

Tomorrow I'll continue through these notes. The next section is on probabilistic approaches, which should line up well with where Prof. Gu will be in her big data lecture tomorrow evening.

## Wednesday, May 17

Today I continued through Ng's [first set of notes](http://cs229.stanford.edu/notes/cs229-notes1.pdf). I followed the end of the Section 2 ("The normal equations") for the derivation of the normal equation, which used many properties of matrices and gradients. I also read Section 3 ("Probabilistic interpretation"), which derived the least squares cost function by assuming that the error is normally distributed, which convinces me that least squares is probably a very good cost function for regression in general. Section 4 ("Locally weighted linear regression") started with a short discussion on the importance of a good fit (not overfitting or underfitting) and of choosing a good set of features for learning. It then talked about the locally weighted linear regression algorithm, which is similar to normal linear regression except that there are weights (w, not θ) for each term in the least squares cost function. The next big part of Ng's notes are about classification and logistic regression, where we try to fit the data to a logistic (sigmoid) function for better classification. 

I also attended Prof. Gu's big data lecture this evening. The first portion of the class was focused on using probability. She talked about the Multivariate Gaussian or normal (MVN) distribution and how to use probability for linear regression. The principle of maximal likelihood was used to choose the weight vector θ that maximizes the likelihood L(θ) or equivalently the log likelihood l(θ) = log L(θ). Then she covered the LMS algorithm, batch gradient descent (BGD), and stochastic gradient descent (SGD). For classification problems, logistic regression is often better than linear regression, once again using the techniques of maximizing log likelihood and _gradient ascent_. Newton's method can also be used, and it is quite fast computationally. Then she started talking about generalized linear models (GLMs), introducing the exponential family of distributions, which includes Bernoulli and Gaussian distributions.

## Thursday, May 18

The [XSEDE big data workshop](https://www.psc.edu/136-users/training/2554-xsede-hpc-workshop-may-18-19-2017-big-data) was pretty informative. One of the speakers talked about [Hadoop](https://www.psc.edu/images/xsedetraining/BigDataMay2017/BigData_Hadoop_051817.pdf), and how it works. It is based on the [Map-Reduce](http://static.googleusercontent.com/media/research.google.com/en//archive/mapreduce-osdi04.pdf) model, where a big problem is split up (parallelized). He did some examples of doing word counts in Shakespeare's works, but this part wasn't very hands-on.

The next (main) speaker talked about [Spark](https://www.psc.edu/images/xsedetraining/BigDataMay2017/Intro_To_Spark.pdf, which is newer than Hadoop and has more capabilities than Hadoop. We were using PySpark since Python is user-friendly and is *very* common for Spark. Spark uses Resilient Distributed Datasets (RDDs) to organized data, and has many ways to manipulate and analyze the data. We saw how to use k-means (a built-in package) in Spark to cluster the data. We then did some Spark exercises to analyze the works of Shakespeare.

At the end, the speaker talked about [Bridges](https://www.psc.edu/images/xsedetraining/BigDataMay2017/A_Big_Big_Data_Platform.pdf), the main supercomputing cluster at PSC that we were using for the workshop. Note that because of this workshop, I now have access to Bridges.

## Friday, May 19

Today was the second day of the [XSEDE big data workshop](https://www.psc.edu/136-users/training/2554-xsede-hpc-workshop-may-18-19-2017-big-data). We first focused on [recommender systems](https://www.psc.edu/images/xsedetraining/BigDataMay2017/A_Recommender_System.pdf) with the Netflix movie recommendation problem in mind. The approach was a lossy compression for an approximate solution, where we take the product of two smaller matrices to fill in rating values in a sparce matrix. The larger the matrices, the more accurate the approximation of the rating matrix will be; the best width/height (a *hyperparameter*) of the smaller matrices can be found experimentally, and if it is too large, we run the risk of overfitting or having it be too computationally expensive. We weren't using singular value decomposition because we are dealing with very large, sparce martrices, and SVD does not deal with this well. Instead we were using the (built-in) Alternating Least Squares (ALS) algorithm. PySpark seems to have many libraries and packages with machine learning algorithms.

The second part of the workshop today was about [deep learning](https://www.psc.edu/images/xsedetraining/BigDataMay2017/Deep_Learning.pdf) and neural networks (NNs). He talked about how NNs are organized and how they work, as well as a taste of how to determine the proper weights in a NN using backpropogation. Stochastic gradient descent is a good, fast way of doing this. TensorFlow was used for Softmax Regression on the MNIST handwritten digits dataset. He covered how convolutions and pooling work which are used for hidden layers in a NN, as well as ways to avoid overfitting.

## Saturday, May 27

This week I finished going through Ng's [first set of notes](http://cs229.stanford.edu/notes/cs229-notes1.pdf). Specifically I looked at Parts II ("Classification and logistic regression") and III ("Generalized Linear Models"). The sections in this part solidified what was taught in the last lecture I attended (on Wednesday, May 17) before I left Claremont.

Logistic regression is a good method for binary classification of data in large part due to the shape of the logistic (sigmoid) function. As with several other approaches, we can use the principle of maximum likelihood as we maximize the log likelihood using stochastic gradient ascent (SGA). We end up with the same rule for SGA as we did for LMS, but now we have a rule defined for a non-linear function. The notes briefly mention that we can get the perceptron learning algorithm by using a specific hypothesis function in the logistic regressin SGA rule, even though perceptron learning is actually very different. The next thing covered was Newton's method, as well as the Newton-Raphson method, a multidimensional version of Newton's method. These methods often converge faster than batch gradient descent. However, finding and inverting an n-by-n Hessian matrix could make Newton-Raphson slower than BGD.

The exponential family includes many common distributions, such as Bernoulli, Gaussian, Poisson, multinomial, among others. All these distributions have a natural (canonical) parameter, a sufficient statistic, a log partition function, which are related in a specific way. I worked through the examples in the notes for the Bernoulli, Gaussian, and multinomial distributions. The notes then talked about Generalized Linear Models (GLMs) with the assumptions that we have an exponential family distribution, that the hypothesis outputs the expected value, and that the natual parameter and inputs are related linearly. The GLM can be applied to a number of different models including ordinary least squares, logistic regression, and softmax regression, which deals with classification into more than than two classes.

## Sunday, May 28

I just discovered that there are [videos](https://www.youtube.com/watch?v=UzxYlbK2c7E&list=PLA89DCFA6ADACE599) of Andrew Ng's CS 229 course from 2008 or so. While these are from almost a decade ago, much of the course seems to be the same as his recent iterations of the course, although I have not done much comparison beyond a [video](https://www.youtube.com/watch?v=qRJ3GKMOFrE) and the corresponding [2016 lecture notes](http://cs229.stanford.edu/notes/cs229-notes2.pdf) on the course website. As I continue reviewing and learning the fundamentals of big data analytics and machine learning, I will probably make use of both the videos and lecture notes, perhaps watching the lecture first and then reading the notes. 

I watched two lectures, but I still want to read the corresponding lecture notes. The [first video](https://www.youtube.com/watch?v=qRJ3GKMOFrE) covered generative learning algorithms, including Gaussian Discriminant Analysis, Naive Bayes, and Laplace smoothing. For the most part I was able to follow this lecture without any trouble. The [second video](https://www.youtube.com/watch?v=qyyJKd-zXRE) went into more depth about Naive Bayes and then went on to neural networks and started talking about support vector machine (SVM). I definitely should go back to the lecture notes and read more about SVM before going on to the next video (which will also be about SVN) because it seems to be a very important algorithm, and I want to understand it well from its mathematical foundation.

I also had a conference call with Prof. Gu so that she could tell me about the project we will be working on. We are going to be trying to develop an algorithm that determines optimal (or near optimal) solutions for a constrained optimization problem. The algorithm will make use of big data to produce the solutions. I'm excited to start working on this project. I'm going to do a preliminary literature review and start a "Statement of Work" to outline what we will be doing for this project. I will also try to look for some example datasets that we can use for our project.

# Saturday, June 3

This week, I shifted my focus away from studying big data analytics (machine learning) basics to learning about algorithms that might be applicable to the problems that I might be dealing with. Since we are dealing with an optimization problem (albiet constrained in a very special way), I started looking into [linear programming](https://en.wikipedia.org/wiki/Linear_programming) which are ways of representing some optimization problems. I learned about linear programming when I took Algorithms, but we mainly dealt with proving that integer linear programming problems are NP-hard; we did not deal with actual algorithms that can solve general linear programming problems. So now I am try to learn algorithms to solve such problems. One algorithm I found was [Dantzig's Simplex Algorithm](https://www.youtube.com/watch?v=RO5477EKlXE), which finds an optimal solution through an iterative process. 

# Sunday, June 4

Today I thought about algorithms that could work for some of the example problems that Prof. Gu mentioned at our call last week. The simplest was perhaps a homework planning problem, where a student has assignments that must be completed by a certain date, and each assignment requires a certain amount of time or work to complete. We want to find the optimal way to arrange how the student is working on the assignments throughout the week even if the student has already done some work on previous days (i.e. the student has done work on Monday and Tuesday and are trying to distribute work for Wednesday, Thursday, and Friday). I think a relatively simple greedy algorithm can find the optimal solution to such a problem, but this is type of algorithm probably will not work for more complicated problems, such as constrained cases of the travelling salesperson problem.

# Sunday, August 6

It's been a long time since I updated this log, but I've been working on scheduling algorithms.

We have decided that the name of the project will be "Adaptive Nested Algorithms for Balanced Scheduling", a name that will appear on a poster to be presented at HMC as well as our anticipated paper.

A couple weeks ago (after pretty much finalizing the personal scheduling algorithms), we started focusing more on larger-scale events (i.e. those that involve multiple attendees). We think that this can be useful for events within an organization, especially where the schedules of the organization members are up-to-date and recorded in some centralized calendar application, such as Google Calendar or Microsoft's Outlook Calendar. It would be ideal if (ultimately) an event organizer could specify some details and constraints about a potential event (desired attendees, acceptable times for the event, etc.), and then an algorithm would propose a good time for the event to be scheduled -- and perhaps be integrated with a calendar application so that it could automatically create calendar invites. I will add more details about my recent progress on this larger-scale scheduling problem tomorrow.

# Monday, August 7

I should mention that the main example that I am using as I work on the larger-scale sceduling problem is still within the context of a college, specifically with the Math department at Harvey Mudd in mind.

While using probabilities of students attending events is a nice, simple, and straightforward algorithm, we would have to deal with a more complicated problem of actually determining those probabilites. I thought that we might be able to represent each student as a vector containing some demographic information (class year, major, etc.) and a version of their own schedule (which would ideally include information from past semesters). A good machine learning option might be a variant of k-Nearest Neighbors, which could be used to calculate probabilites for an individual student if we had access to a large amount of historical data from other students, and also incorporate the student's own personal historic data (to capture preferences or habits). However, kNN is a pretty slow algorithm, so it would not be practical on a larger scale.

The other (less purely machine learning) option is to go with an approach that is much more similar to the previous algorithm I developed for personal scheduling. With this algorithm, I am to some extent trying to mimic the way a human might think as he or she schedules events. Each event is assigned a ranking (which can be learned from historic data). For example, it might have a high priorty (ranking) for students to attend a tutoring session right before an exam, while going to a math club board game event might have a much lower priority. In addition to a priority ranking among attendees, each event has some other details and constraints, such as allowable times, intended/desired attendees. In order to have a more balanced events schedule, it may be desireable for events to be spread out (or at least not too close together), so there might be a constraint that only allows one special events (i.e. events that are not tutoring or office hours) every two or three weeks. It might also be desireable to have a lower bound on the number of special events per semester. (Those can be considered some of the schedule's inherent constraints, rather than event constraints.) Assuming that all necessary details and constraints have been established, the algorithm will first try to assign the events in order of most to least constrained and then by ranking, while also satisfying the schedule's constraints as well as possible.

I am not yet sure how to deal with cases where it may be allowable to have events overlap, as might be the case if there is a special evening lecture that may occur during (or possibly displace) a regular tutoring session. 

With the upcoming deadline (August 21) for submitting posters for the HMC poster session, I will start perparing a poster very soon. I need to find a good way to logically present the algorithms and decide on examples I want to include. I might also need to put some work into graphics for the poster, which will probably include example schedules create by the algorithms.